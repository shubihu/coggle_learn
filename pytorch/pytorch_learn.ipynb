{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be8de9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37dff6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e667420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ef7a798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(2,2), requires_grad=True)\n",
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ac6cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.ones(4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2685030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[:,1] = 0\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8584dbf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量拼接\n",
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9d37fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量乘积\n",
    "tensor.mul(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba8d9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量乘积\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d7f870c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量矩阵乘积\n",
    "tensor.matmul(tensor.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6500ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.],\n",
       "        [3., 3., 3., 3.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量矩阵乘积\n",
    "tensor @ tensor.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11465781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 自动赋值\n",
    "tensor.add_(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9851b461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.],\n",
       "        [6., 5., 6., 6.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "996cf8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6., 5., 6., 6.],\n",
       "       [6., 5., 6., 6.],\n",
       "       [6., 5., 6., 6.],\n",
       "       [6., 5., 6., 6.]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor to numpy\n",
    "tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71396518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy to tensor\n",
    "n = np.ones(5)\n",
    "t = torch.from_numpy(n)\n",
    "# 修改ndarray ,tensor 也随之改变 \n",
    "np.add(n, 1, out=n)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa156cc",
   "metadata": {},
   "source": [
    "# torch.autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b97bcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3c09fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/jiabinwang/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "data = torch.rand(1,3,64,64)\n",
    "labels = torch.rand(1, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "872f76e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be91f3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (prediction - labels).sum()\n",
    "loss.backward()   # backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cf9b0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义优化器，学习率0.01，动量0.9\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b249985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 启动梯度下降\n",
    "optim.step()  # gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf7c352",
   "metadata": {},
   "source": [
    "## autograd 的微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec653d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.tensor([2.,3.], requires_grad=True)\n",
    "b = torch.tensor([6.,4.], requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cd38c113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-12.,  65.], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = 3*a**3 - b**2\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56303c3a",
   "metadata": {},
   "source": [
    "##### torch.autograd跟踪所有将其requires_grad标志设置为True的张量的操作。 对于不需要梯度的张量，将此属性设置为False会将其从梯度计算 DAG 中排除。\n",
    "\n",
    "##### 即使只有一个输入张量具有requires_grad=True，操作的输出张量也将需要梯度。\n",
    "\n",
    "\n",
    "##### 在 NN 中，不计算梯度的参数通常称为冻结参数。 如果事先知道您不需要这些参数的梯度，则“冻结”模型的一部分很有用（通过减少自动梯度计算，这会带来一些性能优势）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "419a65ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "model = torchvision.models.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b54e4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze all the parameters in the network\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094cf202",
   "metadata": {},
   "source": [
    "##### 假设我们要在具有 10 个标签的新数据集中微调模型。 在 resnet 中，分类器是最后一个线性层model.fc。 我们可以简单地将其替换为充当我们的分类器的新线性层（默认情况下未冻结）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecb4d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(512,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f94609b",
   "metadata": {},
   "source": [
    "##### 现在，除了model.fc的参数外，模型中的所有参数都将冻结。 计算梯度的唯一参数是model.fc的权重和偏差。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ffa521d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize only the classifier\n",
    "optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c76ddd",
   "metadata": {},
   "source": [
    "##### torch.no_grad()中的上下文管理器可以使用相同的排除功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8eae1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(5)  # input tensor\n",
    "y = torch.zeros(3)  # expected output\n",
    "w = torch.randn(5, 3, requires_grad=True)\n",
    "b = torch.randn(3, requires_grad=True)\n",
    "z = torch.matmul(x, w)+b\n",
    "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7c67d4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x11e8a6c70>\n"
     ]
    }
   ],
   "source": [
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46571a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BinaryCrossEntropyWithLogitsBackward0 at 0x16a0958b0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cadc048",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31c7d85e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1054, 0.3304, 0.3227],\n",
       "        [0.1054, 0.3304, 0.3227],\n",
       "        [0.1054, 0.3304, 0.3227],\n",
       "        [0.1054, 0.3304, 0.3227],\n",
       "        [0.1054, 0.3304, 0.3227]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66eb3c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1054, 0.3304, 0.3227])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bf8c2e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    z = torch.matmul(x, w)+b\n",
    "print(z.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863b1cd",
   "metadata": {},
   "source": [
    "##### 使用numpy创建一个y=10*x+4+noise(0,1)的数据，其中x是0到100的范围，以0.01进行等差数列\n",
    "##### 使用pytorch定义w和b，并使用随机梯度下降，完成回归拟合。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "292c9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "05348b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self, w, b):\n",
    "        super(Mlp, self).__init__()\n",
    "        self.w = nn.Parameter(w)  # 初始化参数\n",
    "        self.b = nn.Parameter(b)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.matmul(x, self.w) + self.b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "863fe0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = torch.tensor([[1.]])\n",
    "b = torch.tensor([1.])\n",
    "x = np.arange(0, 100, 0.01)\n",
    "noise = np.random.normal(0, 1, len(x))  # (0,1)的高斯噪声\n",
    "y = 10 * x + 4 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0723636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(x).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "x = torch.unsqueeze(x, dim=1) # 转换[1,10000]为[10000,1]\n",
    "y = torch.unsqueeze(y, dim=1)  # 转换[1,10000]为[10000,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3936a496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, loss is 272658.625\n",
      "epoch:1000, loss is 2.878840923309326\n",
      "epoch:2000, loss is 2.6988868713378906\n",
      "epoch:3000, loss is 2.536067008972168\n",
      "epoch:4000, loss is 2.388726234436035\n",
      "epoch:5000, loss is 2.2554266452789307\n",
      "epoch:6000, loss is 2.1348049640655518\n",
      "epoch:7000, loss is 2.0256617069244385\n",
      "epoch:8000, loss is 1.9269031286239624\n",
      "epoch:9000, loss is 1.8375498056411743\n"
     ]
    }
   ],
   "source": [
    "model = Mlp(w, b)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "for epoch in range(10000):\n",
    "    y_pre = model(x)\n",
    "    loss = criterion(y_pre, y)\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'epoch:{epoch}, loss is {loss}')\n",
    "    \n",
    "    optimizer.zero_grad() # 梯度清零\n",
    "    loss.backward()  # 反向传播计算梯度\n",
    "    optimizer.step() # 更新参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3a921c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w的值为 10.025729179382324\n",
      "b的值为 2.273160219192505\n"
     ]
    }
   ],
   "source": [
    "print('w的值为', model.w.item())\n",
    "print('b的值为', model.b.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49079eeb",
   "metadata": {},
   "source": [
    "##### 在pytorch中使用矩阵乘法实现全连接层\n",
    "##### 在pytorch中使用nn.Linear层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d4bb7358",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Myliner(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(Myliner, self).__init__()\n",
    "        self.w = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        self.b = nn.Parameter(torch.Tensor(out_features))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x @ self.w.t() + self.b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e37a0b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:torch.Size([10, 784])\n",
      "b:torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "model = Myliner(784, 10)\n",
    "x = torch.rand(100, 784)\n",
    "out = model(x)\n",
    "\n",
    "for n, p in model.named_parameters():\n",
    "    print(f'{n}:{p.shape}')\n",
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4339401f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "class linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(linear, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7e2052af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc.weight:torch.Size([10, 784])\n",
      "fc.bias:torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "model = linear(784, 10)\n",
    "x = torch.rand(100, 784)\n",
    "out = model(x)\n",
    "\n",
    "for n, p in model.named_parameters():\n",
    "    print(f'{n}:{p.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034e09de",
   "metadata": {},
   "source": [
    "## 激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b3cd6464",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LeakyRelu(x, negative_slope=0.01, inplace=False):\n",
    "    return max(0, x) + negative_slope * min(0, x)\n",
    "\n",
    "def Relu(x, inplace=False):\n",
    "    return max(0, x)\n",
    "\n",
    "def Sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def LogSigmoid(x):\n",
    "    return np.log(1.0 / (1.0 + np.exp(-x)))\n",
    "\n",
    "def Tanh(x):\n",
    "    return (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110e0a75",
   "metadata": {},
   "source": [
    "## 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cae7bded",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算下如下卷积层的参数量\n",
    "nn.Conv2d(            \n",
    "        in_channels=1,            \n",
    "        out_channels=32,            \n",
    "        kernel_size=5,            \n",
    "        stride=1,            \n",
    "        padding=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8845891a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "832"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(            \n",
    "        in_channels=1,            \n",
    "        out_channels=32,            \n",
    "        kernel_size=5,            \n",
    "        stride=1,            \n",
    "        padding=2\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv1(x)\n",
    "    \n",
    "model = Net()\n",
    "# p = sum(map(lambda p:p.numel(), model.parameters()))\n",
    "p = sum(p.numel() for p in list(model.parameters()))\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea7f0fe",
   "metadata": {},
   "source": [
    "# PyTorch常见的损失函数和优化器使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a099e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class linear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(linear, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc(x)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a31a791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(4, 3)\n",
    "w = torch.randint(5, 10, size=(3, 1), dtype=torch.float)\n",
    "b = torch.tensor(5.)\n",
    "noise = torch.randn(4, 1)\n",
    "y = x @ w + b + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc30d4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0,loss is:11.14564037322998\n",
      "Epoch:1000,loss is:4.220623850414995e-12\n",
      "Epoch:2000,loss is:4.220623850414995e-12\n",
      "Epoch:3000,loss is:4.220623850414995e-12\n",
      "Epoch:4000,loss is:4.220623850414995e-12\n",
      "Epoch:5000,loss is:4.220623850414995e-12\n",
      "Epoch:6000,loss is:4.220623850414995e-12\n",
      "Epoch:7000,loss is:4.220623850414995e-12\n",
      "Epoch:8000,loss is:4.220623850414995e-12\n",
      "Epoch:9000,loss is:4.220623850414995e-12\n",
      "Epoch:0,loss is:12.907681465148926\n",
      "Epoch:1000,loss is:4.901413558400236e-05\n",
      "Epoch:2000,loss is:2.15831619243545e-09\n",
      "Epoch:3000,loss is:1.6082424281194108e-10\n",
      "Epoch:4000,loss is:1.6082424281194108e-10\n",
      "Epoch:5000,loss is:1.6082424281194108e-10\n",
      "Epoch:6000,loss is:1.6082424281194108e-10\n",
      "Epoch:7000,loss is:1.6082424281194108e-10\n",
      "Epoch:8000,loss is:1.6082424281194108e-10\n",
      "Epoch:9000,loss is:1.6082424281194108e-10\n",
      "Epoch:0,loss is:11.111713409423828\n",
      "Epoch:1000,loss is:0.6043795347213745\n",
      "Epoch:2000,loss is:0.2198248952627182\n",
      "Epoch:3000,loss is:0.0800929069519043\n",
      "Epoch:4000,loss is:0.029181940481066704\n",
      "Epoch:5000,loss is:0.01063242182135582\n",
      "Epoch:6000,loss is:0.0038739372976124287\n",
      "Epoch:7000,loss is:0.0014115514932200313\n",
      "Epoch:8000,loss is:0.0005143547896295786\n",
      "Epoch:9000,loss is:0.00018747654394246638\n",
      "{0.5: {'loss': 4.220623850414995e-12, 'epoch': 520}, 0.1: {'loss': 1.6082424281194108e-10, 'epoch': 2270}, 0.01: {'loss': 6.84468395775184e-05, 'epoch': 9999}}\n"
     ]
    }
   ],
   "source": [
    "res = {}\n",
    "for lr in [0.5, 0.1, 0.01]:\n",
    "    best_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "    model = linear(3, 1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    for epoch in range(10000):\n",
    "        y_pre = model(x)\n",
    "        loss = criterion(y_pre, y)\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f'Epoch:{epoch},loss is:{loss}')\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "            best_epoch = epoch\n",
    "    res[lr] = {'loss':best_loss.item(), 'epoch':best_epoch}\n",
    "    \n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76629222",
   "metadata": {},
   "source": [
    "# PyTorch池化层和归一化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a625a0f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 10, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "x = torch.randn(10, 3, 32, 32)\n",
    "avg = nn.AvgPool2d(3, 3)\n",
    "avg(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25719728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 9, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxp = nn.MaxPool2d(7, 3)\n",
    "maxp(x).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
