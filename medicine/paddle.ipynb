{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae54b3b6-5b1d-4a64-ab9f-e067688da8d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T07:34:02.707897Z",
     "iopub.status.busy": "2021-11-29T07:34:02.707251Z",
     "iopub.status.idle": "2021-11-29T07:34:04.991189Z",
     "shell.execute_reply": "2021-11-29T07:34:04.989982Z",
     "shell.execute_reply.started": "2021-11-29T07:34:02.707843Z"
    }
   },
   "outputs": [],
   "source": [
    "import codecs, glob, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "\n",
    "import paddle.nn.functional as F\n",
    "import paddle\n",
    "import paddle.nn as nn\n",
    "from paddle.io import DataLoader, Dataset\n",
    "import paddle.optimizer as optim\n",
    "from paddlenlp.data import Pad\n",
    "\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36216edd-21c3-404e-8ab6-303e99a91648",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T07:34:07.905785Z",
     "iopub.status.busy": "2021-11-29T07:34:07.905275Z",
     "iopub.status.idle": "2021-11-29T07:34:07.917901Z",
     "shell.execute_reply": "2021-11-29T07:34:07.917246Z",
     "shell.execute_reply.started": "2021-11-29T07:34:07.905748Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './'\n",
    "df = pd.read_csv(path+'trainreference.csv')\n",
    "class myDataset(Dataset):\n",
    "    def __init__(self, df, idx=None, if_train=True):\n",
    "        self.if_train = if_train\n",
    "        if self.if_train:\n",
    "            self.paths = df.loc[idx, 'name'].reset_index(drop=True)\n",
    "            self.labels = df.loc[idx, 'tag'].reset_index(drop=True)\n",
    "        else:\n",
    "            self.paths = df['name'].reset_index(drop=True)\n",
    "            self.labels = df['tag'].reset_index(drop=True)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.if_train:\n",
    "            sample = sio.loadmat(path+'train/'+self.paths[index])['ecgdata']\n",
    "        else:\n",
    "            sample = sio.loadmat(path+'val/'+self.paths[index])['ecgdata']\n",
    "        return sample, self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd0872a-4481-4167-aea3-f865ba0cd89c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T07:34:11.234610Z",
     "iopub.status.busy": "2021-11-29T07:34:11.233444Z",
     "iopub.status.idle": "2021-11-29T07:34:11.243172Z",
     "shell.execute_reply": "2021-11-29T07:34:11.242178Z",
     "shell.execute_reply.started": "2021-11-29T07:34:11.234556Z"
    }
   },
   "outputs": [],
   "source": [
    "class SeqNet(nn.Layer):\n",
    "    def __init__(self):\n",
    "        super(SeqNet, self).__init__()\n",
    "        # input \n",
    "        self.conv1 = nn.Conv1D(12, 10, 50)\n",
    "        self.conv2 = nn.Conv1D(12, 10, 200)\n",
    "        self.conv3 = nn.Conv1D(12, 10, 500)\n",
    "        self.conv4 = nn.Conv1D(12, 10, 1000)\n",
    "        # self.pooling = nn.MaxPool2D((1, 200))\n",
    "        self.pooling = nn.MaxPool1D(200)\n",
    "        self.fc1 = nn.Linear(900, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        out1 = self.pooling(F.relu(self.conv1(x)))\n",
    "        out2 = self.pooling(F.relu(self.conv2(x)))\n",
    "        out3 = self.pooling(F.relu(self.conv3(x)))\n",
    "        out4 = self.pooling(F.relu(self.conv4(x)))\n",
    "\n",
    "        # # out = torch.cat([out1, out2, out3, out4], 2)  \n",
    "        out = paddle.concat([out1, out2, out3, out4], 2)\n",
    "        # out = out.view(batch_size, -1)\n",
    "        out = paddle.reshape(out, [batch_size, -1])\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = F.dropout(out, p=0.6)\n",
    "        out = self.fc2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8985e1a3-faac-4bd2-8d56-7708c8985511",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T07:34:17.495279Z",
     "iopub.status.busy": "2021-11-29T07:34:17.494702Z",
     "iopub.status.idle": "2021-11-29T07:34:17.512437Z",
     "shell.execute_reply": "2021-11-29T07:34:17.511634Z",
     "shell.execute_reply.started": "2021-11-29T07:34:17.495237Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "max_epoch = 200\n",
    "batch_size = 32\n",
    "model_save_dir = path+'model/'\n",
    "def train_model(model, criterion, optimizer, lr_scheduler=None):\n",
    "    total_iters=len(trainloader)\n",
    "    print('--------------total_iters:{}'.format(total_iters))\n",
    "    since = time.time()\n",
    "    best_loss = 1e7\n",
    "    best_epoch = 0\n",
    "    best_f1 = 0\n",
    "    #\n",
    "    iters = len(trainloader)\n",
    "    for epoch in range(1,max_epoch+1):\n",
    "        model.train()\n",
    "        begin_time=time.time()\n",
    "        # print('learning rate:{}'.format(optimizer.param_groups[-1]['lr']))\n",
    "        # print('Fold{} Epoch {}/{}'.format(fold+1,epoch, max_epoch))\n",
    "        running_corrects_linear = 0\n",
    "        count=0\n",
    "        train_loss = []\n",
    "        for i, (inputs, labels) in (enumerate(trainloader)):\n",
    "            # print(inputs)\n",
    "            count+=1\n",
    "            # inputs = inputs.to(device)\n",
    "            inputs = inputs.cuda()\n",
    "            # labels = labels.float().to(device)\n",
    "            labels = labels.cuda()\n",
    "            # labels = paddle.reshape(labels, (30, 1))\n",
    "            labels = paddle.cast(labels, dtype='float32')\n",
    "\n",
    "            out_linear = model(inputs)\n",
    "            out_linear = paddle.reshape(out_linear, (batch_size,))\n",
    "            loss = criterion(out_linear, labels)\n",
    "            # loss = criterion(out_linear, labels.unsqueeze(1))\n",
    "\n",
    "            # optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.clear_grad()\n",
    "            # 更新cosine学习率\n",
    "            if lr_scheduler!=None:\n",
    "                lr_scheduler.step(epoch + count / iters)\n",
    "            if print_interval>0 and (i % print_interval == 0 or out_linear.size()[0] < train_batch_size):\n",
    "                spend_time = time.time() - begin_time\n",
    "                if epoch % 50 == 0:\n",
    "                    print(\n",
    "                    ' Fold:{} Epoch:{}({}/{}) loss:{:.3f} lr:{:.7f} epoch_Time:{}min:'.format(\n",
    "                        fold+1,epoch, count, total_iters,\n",
    "                        loss.item(), optimizer.param_groups[-1]['lr'],\n",
    "                        spend_time / count * total_iters // 60 - spend_time // 60))\n",
    "            #\n",
    "            train_loss.append(loss.item())\n",
    "        #lr_scheduler.step()\n",
    "        val_f1, val_loss= val_model(model, criterion)\n",
    "        if epoch % 50 == 0:\n",
    "            print('valf1: {:.4f}  valLogLoss: {:.4f}'.format(val_f1, val_loss))\n",
    "        model_out_path = model_save_dir+\"/\"+'fold_'+str(fold+1)+'_'+str(epoch) + '.pth'\n",
    "        best_model_out_path = model_save_dir+\"/\"+'fold_'+str(fold+1)+'_best'+'.pth'\n",
    "        #save the best model\n",
    "        if val_f1 >= best_f1:\n",
    "            best_loss = val_loss\n",
    "            best_f1 = val_f1\n",
    "            best_epoch=epoch\n",
    "            paddle.save(model.state_dict(), best_model_out_path)\n",
    "            if epoch % 50 == 0:\n",
    "                print(\"save best epoch: {} best f1: {:.5f} best logloss: {:.5f}\".format(best_epoch,val_f1,val_loss))\n",
    "  \n",
    "    print('Fold{} Best f1: {:.3f} Best logloss: {:.3f} Best epoch:{}'.format(fold+1,best_f1, best_loss,best_epoch))\n",
    "    time_elapsed = time.time() - since\n",
    "    return best_loss, best_f1\n",
    "\n",
    "@paddle.no_grad()\n",
    "def val_model(model, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    cont = 0\n",
    "    outPre = []\n",
    "    outLabel = []\n",
    "    pres_list=[]\n",
    "    labels_list=[]\n",
    "    for data in val_loader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        outputs = model(inputs)\n",
    "        # pres_list+=outputs.sigmoid().detach().cpu().numpy().tolist()\n",
    "        pres_list+=paddle.nn.functional.sigmoid(outputs).detach().cpu().numpy().tolist()\n",
    "        labels_list+=labels.detach().cpu().numpy().tolist()\n",
    "\n",
    "    preds = np.array(pres_list)\n",
    "    labels = np.array(labels_list)\n",
    "    val_f1 = metrics.f1_score(labels, list(map(lambda x: 1 if x > 0.5 else 0, preds)))\n",
    "    log_loss = metrics.log_loss(labels, preds)#\n",
    "    return val_f1, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e30c568-643e-49b5-aa60-0a5122b1c92a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T07:34:20.828846Z",
     "iopub.status.busy": "2021-11-29T07:34:20.827534Z",
     "iopub.status.idle": "2021-11-29T07:34:20.844730Z",
     "shell.execute_reply": "2021-11-29T07:34:20.843790Z",
     "shell.execute_reply.started": "2021-11-29T07:34:20.828768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu:0\n"
     ]
    }
   ],
   "source": [
    "# def setup_seed(seed):\n",
    "#      torch.manual_seed(seed)\n",
    "#      torch.cuda.manual_seed_all(seed)\n",
    "#      np.random.seed(seed)\n",
    "#      random.seed(seed)\n",
    "#      torch.backends.cudnn.deterministic = True\n",
    "# setup_seed(2021)\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = paddle.device.get_device()\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d2e1b6e0-28f1-4899-9fbc-a47f8d61ae4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T05:44:19.789002Z",
     "iopub.status.busy": "2021-11-29T05:44:19.788090Z",
     "iopub.status.idle": "2021-11-29T05:44:19.792604Z",
     "shell.execute_reply": "2021-11-29T05:44:19.791603Z",
     "shell.execute_reply.started": "2021-11-29T05:44:19.788964Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train_Loader = DataLoader(\n",
    "#                 myDataset(df, [i for i in range(1200)]), \n",
    "#                 batch_size=30, shuffle=True)\n",
    "# for i in Train_Loader:\n",
    "#     x1 = i[0]\n",
    "#     y1 = i[1]\n",
    "#     x1 = x1.cuda()\n",
    "#     y1 = y1.cuda()\n",
    "    \n",
    "#     break\n",
    "# x1.shape\n",
    "# x1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a0b28ff-a8b9-4848-8264-a1be36786d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T05:44:26.171395Z",
     "iopub.status.busy": "2021-11-29T05:44:26.170525Z",
     "iopub.status.idle": "2021-11-29T05:44:26.174932Z",
     "shell.execute_reply": "2021-11-29T05:44:26.174141Z",
     "shell.execute_reply.started": "2021-11-29T05:44:26.171357Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = SeqNet()\n",
    "# model.to(device)\n",
    "# out = model(x1)\n",
    "# out = paddle.reshape(out, (30,))\n",
    "# print(out)\n",
    "# # y1 = paddle.reshape(y1, (30, 1))\n",
    "# y1 = paddle.cast(y1, dtype='float32')\n",
    "# print(y1)\n",
    "\n",
    "\n",
    "# # loss = paddle.mean(out)\n",
    "# criterion = nn.BCEWithLogitsLoss()\n",
    "# loss = criterion(out, y1)\n",
    "# print(loss)\n",
    "# adam = paddle.optimizer.AdamW(weight_decay=0.01, learning_rate=0.1,\n",
    "#         parameters=model.parameters())\n",
    "# out.backward()\n",
    "# adam.step()\n",
    "# adam.clear_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2023e67b-83ff-44ac-9745-3ba2312180e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T07:34:26.055802Z",
     "iopub.status.busy": "2021-11-29T07:34:26.054801Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1129 15:34:26.066895 11426 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 10.1, Runtime API Version: 10.1\n",
      "W1129 15:34:26.071918 11426 device_context.cc:422] device: 0, cuDNN Version: 7.6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------total_iters:45\n",
      "valf1: 0.8163  valLogLoss: 0.4785\n",
      "valf1: 0.8344  valLogLoss: 0.7376\n",
      "valf1: 0.8313  valLogLoss: 0.9174\n",
      "valf1: 0.7925  valLogLoss: 1.1313\n",
      "Fold1 Best f1: 0.859 Best logloss: 0.755 Best epoch:69\n",
      "--------------total_iters:45\n",
      "valf1: 0.8098  valLogLoss: 0.4831\n",
      "valf1: 0.8199  valLogLoss: 0.9267\n",
      "valf1: 0.7925  valLogLoss: 1.2028\n",
      "valf1: 0.8589  valLogLoss: 1.0469\n",
      "Fold2 Best f1: 0.861 Best logloss: 0.555 Best epoch:171\n",
      "--------------total_iters:45\n",
      "valf1: 0.8302  valLogLoss: 0.8840\n",
      "valf1: 0.8375  valLogLoss: 1.4171\n",
      "valf1: 0.7500  valLogLoss: 2.3256\n",
      "valf1: 0.8101  valLogLoss: 1.9320\n",
      "Fold3 Best f1: 0.861 Best logloss: 1.023 Best epoch:83\n",
      "--------------total_iters:45\n",
      "valf1: 0.7927  valLogLoss: 0.5031\n",
      "valf1: 0.7950  valLogLoss: 0.6513\n",
      "valf1: 0.8125  valLogLoss: 0.7518\n",
      "valf1: 0.7831  valLogLoss: 0.9152\n",
      "Fold4 Best f1: 0.834 Best logloss: 0.666 Best epoch:86\n",
      "--------------total_iters:45\n",
      "valf1: 0.7871  valLogLoss: 0.4865\n",
      "valf1: 0.8153  valLogLoss: 0.7650\n",
      "valf1: 0.8344  valLogLoss: 0.9777\n",
      "valf1: 0.8101  valLogLoss: 1.2405\n",
      "Fold5 Best f1: 0.863 Best logloss: 0.587 Best epoch:90\n",
      "--------------total_iters:45\n",
      "valf1: 0.8095  valLogLoss: 0.4466\n",
      "valf1: 0.8024  valLogLoss: 0.8216\n",
      "valf1: 0.8228  valLogLoss: 0.7350\n",
      "valf1: 0.8228  valLogLoss: 0.8946\n",
      "Fold6 Best f1: 0.855 Best logloss: 0.398 Best epoch:62\n",
      "--------------total_iters:45\n",
      "valf1: 0.7945  valLogLoss: 0.5655\n",
      "valf1: 0.7722  valLogLoss: 1.1300\n",
      "valf1: 0.7636  valLogLoss: 1.3097\n",
      "valf1: 0.7898  valLogLoss: 1.7044\n",
      "Fold7 Best f1: 0.850 Best logloss: 0.793 Best epoch:117\n",
      "--------------total_iters:45\n",
      "valf1: 0.8258  valLogLoss: 0.5750\n",
      "valf1: 0.8250  valLogLoss: 0.8277\n",
      "valf1: 0.8408  valLogLoss: 0.8995\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "print_interval=-1\n",
    "kfold_best_loss = []\n",
    "kfold_best_f1 = []\n",
    "# print(len(df))\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['tag'].values)):\n",
    "    trainloader = DataLoader(\n",
    "        myDataset(df, train_idx), \n",
    "        batch_size=32, shuffle=True, num_workers=1)\n",
    "    val_loader = DataLoader(\n",
    "        myDataset(df, val_idx), \n",
    "        batch_size=128, shuffle=False, num_workers=1)\n",
    "    model = SeqNet()\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(learning_rate=1e-4, parameters=model.parameters(),weight_decay=5e-4)\n",
    "    # # optimizer = optim.Adam(parameters=model.parameters(), learning_rate=1e-4)\n",
    "    scheduler = optim.lr.CosineAnnealingDecay(1e-4, T_max=max_epoch)\n",
    "\n",
    "    best_loss, best_acc = train_model(model, criterion, optimizer, lr_scheduler=scheduler)\n",
    "    kfold_best_loss.append(best_loss)\n",
    "    kfold_best_f1.append(best_acc)\n",
    "\n",
    "print(kfold_best_f1)                  \n",
    "print('loss...', np.mean(kfold_best_loss), 'f1...', np.mean(kfold_best_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5fc95fd4-1c63-42ea-94f5-8c2410ee2d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T05:11:59.356557Z",
     "iopub.status.busy": "2021-11-29T05:11:59.355476Z",
     "iopub.status.idle": "2021-11-29T05:11:59.364416Z",
     "shell.execute_reply": "2021-11-29T05:11:59.363668Z",
     "shell.execute_reply.started": "2021-11-29T05:11:59.356517Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import os\n",
    "def load_model(weight_path):\n",
    "    print(weight_path)\n",
    "    model = SeqNet()\n",
    "    model.set_state_dict(paddle.load(weight_path))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "@paddle.no_grad()\n",
    "def predict(test_loader):\n",
    "    ret = 0\n",
    "    for i, model in enumerate(model_list):\n",
    "        print('----model ', i)\n",
    "        pres_list = []\n",
    "        for data in tqdm(test_loader):\n",
    "            inputs, _a = data\n",
    "            inputs = inputs.cuda()\n",
    "            outputs = model(inputs)\n",
    "            pres_list+=F.sigmoid(outputs).detach().cpu().numpy().tolist()\n",
    "        ret += np.array(pres_list) / len(model_list)\n",
    "    return list(map(lambda x: 1 if x > 0.5 else 0, ret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "3812410f-fed7-4052-86b3-fc86de61b6b5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T05:12:02.759743Z",
     "iopub.status.busy": "2021-11-29T05:12:02.758641Z",
     "iopub.status.idle": "2021-11-29T05:12:27.265914Z",
     "shell.execute_reply": "2021-11-29T05:12:27.265085Z",
     "shell.execute_reply.started": "2021-11-29T05:12:02.759704Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./model/fold_1_best.pth\n",
      "./model/fold_2_best.pth\n",
      "./model/fold_3_best.pth\n",
      "./model/fold_4_best.pth\n",
      "./model/fold_5_best.pth\n",
      "./model/fold_6_best.pth\n",
      "./model/fold_7_best.pth\n",
      "./model/fold_8_best.pth\n",
      "./model/fold_9_best.pth\n",
      "./model/fold_10_best.pth\n",
      "----model  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----model  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:02<00:00,  2.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VAL0001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VAL0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VAL0003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VAL0004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VAL0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  tag\n",
       "0  VAL0001    1\n",
       "1  VAL0002    1\n",
       "2  VAL0003    1\n",
       "3  VAL0004    0\n",
       "4  VAL0005    1"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device=torch.device('cuda')\n",
    "model_list=[]\n",
    "for i in range(10):\n",
    "    model_list.append(load_model(path+'model/fold_'+str(i+1)+'_best.pth'))\n",
    "import os\n",
    "\n",
    "sub = pd.read_csv(path+'answer.csv')\n",
    "test_loader = DataLoader(\n",
    "        myDataset(sub, if_train=False), \n",
    "        batch_size=64, shuffle=False, num_workers=16)\n",
    "sub['tag'] = predict(test_loader)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fbf51aab-b0cb-4a76-bec0-3cb54db16ac6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-29T05:13:53.990763Z",
     "iopub.status.busy": "2021-11-29T05:13:53.990155Z",
     "iopub.status.idle": "2021-11-29T05:13:54.810082Z",
     "shell.execute_reply": "2021-11-29T05:13:54.809195Z",
     "shell.execute_reply.started": "2021-11-29T05:13:53.990723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: answer.csv (deflated 80%)\n"
     ]
    }
   ],
   "source": [
    "sub.to_csv(path+'answer.csv', index=False)\n",
    "!rm -rf  answer.csv.zip\n",
    "!zip answer.csv.zip answer.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93ad04e-9661-4352-b0a6-15d78ebb0fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
